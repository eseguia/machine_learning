{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "### Housing Price Prediction\n",
    "\n",
    "The goal of this competition entry is apply concepts I've learnt so far, and gain more practise in feature engineering and stacked models.\n",
    "\n",
    "As the missing features of this dataset are rather sparse, engineering them will mainly mean:\n",
    "\n",
    "* Imputing missing values\n",
    "* Dealing with outliers\n",
    "* Transforming variables\n",
    "* Label Encoding\n",
    "* Stabilizing variance/skewness\n",
    "* Aquiring dummy variables\n",
    "\n",
    "Model will be a sklearn base + XGBoost + LightGBM stack predicting the **SalePrice**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits & Inspiration\n",
    "* [Stacked Regression by Serigne](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard/notebook) - Absolutely stunning notebook that I've used as the template for my own explorations here. Taught me a lot about feature engineering and stacked modelling.\n",
    "* [Stacking Ensemble Machine Learning With Python by Jason Brownlee](https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/) - Great tutorial on stacking models\n",
    "* [Comprehensive data exploration with Python by Pedro Marcelino](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) - In-depth EDA on this dataset\n",
    "* [A study on Regression applied to the Ames dataset by juliencs](https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset) - Great notebook using linear regression on this dataset\n",
    "* [Missing Values, Ordinal data and stories\n",
    " by mitra mirshafiee](https://www.kaggle.com/mitramir5/missing-values-ordinal-data-and-stories) - Illustrative and educational notebook on handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:42.879488Z",
     "iopub.status.busy": "2022-01-19T22:39:42.878987Z",
     "iopub.status.idle": "2022-01-19T22:39:42.891299Z",
     "shell.execute_reply": "2022-01-19T22:39:42.890432Z",
     "shell.execute_reply.started": "2022-01-19T22:39:42.879457Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10904/972032997.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12,6]\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "#Float Output to 2 decimals\n",
    "pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x))\n",
    "\n",
    "#Models\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Quality of life\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:42.894099Z",
     "iopub.status.busy": "2022-01-19T22:39:42.893716Z",
     "iopub.status.idle": "2022-01-19T22:39:42.945191Z",
     "shell.execute_reply": "2022-01-19T22:39:42.94439Z",
     "shell.execute_reply.started": "2022-01-19T22:39:42.894053Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing datasets\n",
    "train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:42.947242Z",
     "iopub.status.busy": "2022-01-19T22:39:42.946756Z",
     "iopub.status.idle": "2022-01-19T22:39:42.975656Z",
     "shell.execute_reply": "2022-01-19T22:39:42.975046Z",
     "shell.execute_reply.started": "2022-01-19T22:39:42.947197Z"
    }
   },
   "outputs": [],
   "source": [
    "#First look training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:42.977065Z",
     "iopub.status.busy": "2022-01-19T22:39:42.976529Z",
     "iopub.status.idle": "2022-01-19T22:39:42.998666Z",
     "shell.execute_reply": "2022-01-19T22:39:42.997945Z",
     "shell.execute_reply.started": "2022-01-19T22:39:42.977032Z"
    }
   },
   "outputs": [],
   "source": [
    "#First look test set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:43.000957Z",
     "iopub.status.busy": "2022-01-19T22:39:43.000628Z",
     "iopub.status.idle": "2022-01-19T22:39:43.014379Z",
     "shell.execute_reply": "2022-01-19T22:39:43.013572Z",
     "shell.execute_reply.started": "2022-01-19T22:39:43.000922Z"
    }
   },
   "outputs": [],
   "source": [
    "#Saving then dropping Id column as it does not impact our prediction\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:43.015896Z",
     "iopub.status.busy": "2022-01-19T22:39:43.015334Z",
     "iopub.status.idle": "2022-01-19T22:39:43.270437Z",
     "shell.execute_reply": "2022-01-19T22:39:43.269555Z",
     "shell.execute_reply.started": "2022-01-19T22:39:43.015843Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualizing outliers, seen in bottom right.\n",
    "sns.scatterplot(data=train, x='GrLivArea', y='SalePrice');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:43.272535Z",
     "iopub.status.busy": "2022-01-19T22:39:43.272051Z",
     "iopub.status.idle": "2022-01-19T22:39:43.281291Z",
     "shell.execute_reply": "2022-01-19T22:39:43.280494Z",
     "shell.execute_reply.started": "2022-01-19T22:39:43.272485Z"
    }
   },
   "outputs": [],
   "source": [
    "#the vast difference between 2 values of GrLivArea over 4000 and SalePrice under 200000 and the rest of datapoints makes me believe these outliers are safe to remove from the training set\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<200000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:43.282644Z",
     "iopub.status.busy": "2022-01-19T22:39:43.282448Z",
     "iopub.status.idle": "2022-01-19T22:39:43.54771Z",
     "shell.execute_reply": "2022-01-19T22:39:43.546737Z",
     "shell.execute_reply.started": "2022-01-19T22:39:43.28262Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualizing outliers, seen in bottom right.\n",
    "sns.scatterplot(data=train, x='GrLivArea', y='SalePrice');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:43.550179Z",
     "iopub.status.busy": "2022-01-19T22:39:43.549335Z",
     "iopub.status.idle": "2022-01-19T22:39:44.070479Z",
     "shell.execute_reply": "2022-01-19T22:39:44.069548Z",
     "shell.execute_reply.started": "2022-01-19T22:39:43.550133Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['SalePrice'] , fit=norm);\n",
    "\n",
    "#Fitted parameters used by function\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "\n",
    "#Visualize Normal Distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.0f} and $\\sigma=$ {:.0f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Visualize Quantile-Quantile plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is right skewed, which is a problem for our model as it needs to be normally distributed. This means we need to apply a Log transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T08:02:56.058218Z",
     "iopub.status.busy": "2022-01-17T08:02:56.057931Z",
     "iopub.status.idle": "2022-01-17T08:02:56.062514Z",
     "shell.execute_reply": "2022-01-17T08:02:56.061625Z",
     "shell.execute_reply.started": "2022-01-17T08:02:56.058186Z"
    }
   },
   "source": [
    "### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:44.072166Z",
     "iopub.status.busy": "2022-01-19T22:39:44.071923Z",
     "iopub.status.idle": "2022-01-19T22:39:44.615566Z",
     "shell.execute_reply": "2022-01-19T22:39:44.614918Z",
     "shell.execute_reply.started": "2022-01-19T22:39:44.072122Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using numpy log1p fuction, which applies log(1+x) to elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "sns.distplot(train['SalePrice'] , fit=norm);\n",
    "\n",
    "#Fitted parameters used by function\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "\n",
    "#Visualize Normal Distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Visualize Quantile-Quantile plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SalePrice has been transformed to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:44.617148Z",
     "iopub.status.busy": "2022-01-19T22:39:44.61679Z",
     "iopub.status.idle": "2022-01-19T22:39:45.622563Z",
     "shell.execute_reply": "2022-01-19T22:39:45.621537Z",
     "shell.execute_reply.started": "2022-01-19T22:39:44.617118Z"
    }
   },
   "outputs": [],
   "source": [
    "#Correlation map to understand how other features relate to SalePrice\n",
    "corrmat = train.corr()\n",
    "mask = np.zeros_like(corrmat)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(corrmat, mask=mask, ax=ax, cbar_kws={\"shrink\": .82},vmax=.9, cmap='coolwarm', square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately spot how the OverallQual and GrLivArea features have the high positive correlation with SalePrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Concatenating training and test set into same dataframe for preprocessing. Our feature engineering mainly revolves around harmonizing values so they more accurately reflect reality, whilst increasing predictions.\n",
    "\n",
    "*version 6 note: **data leakage will occur** since we impute values based on test+train datasets, leading to a too optimistic score. In future version we will calculate compute missing values and apply Box-Cox seperately.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:45.624283Z",
     "iopub.status.busy": "2022-01-19T22:39:45.62369Z",
     "iopub.status.idle": "2022-01-19T22:39:45.648774Z",
     "shell.execute_reply": "2022-01-19T22:39:45.648096Z",
     "shell.execute_reply.started": "2022-01-19T22:39:45.624242Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating index for splitting datasets\n",
    "i_train = train.shape[0]\n",
    "i_test = test.shape[0]\n",
    "\n",
    "#Setting y_train\n",
    "y_train = train.SalePrice.values\n",
    "\n",
    "#Concatenating datasets\n",
    "df_concat = pd.concat((train, test)).reset_index(drop=True)\n",
    "df_concat.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "#Printing shape of datasets\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(df_concat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:45.650314Z",
     "iopub.status.busy": "2022-01-19T22:39:45.649764Z",
     "iopub.status.idle": "2022-01-19T22:39:45.669632Z",
     "shell.execute_reply": "2022-01-19T22:39:45.668607Z",
     "shell.execute_reply.started": "2022-01-19T22:39:45.650278Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating dataframe with percentages of missing values\n",
    "df_concat_na = (df_concat.isnull().sum() / len(df_concat)) * 100\n",
    "\n",
    "#Sorting by percentages of missing values\n",
    "df_concat_na = df_concat_na.sort_values(ascending=False)[:20] #values of missing percentages after index 20 drop to around 0.03.. \n",
    "\n",
    "missing_values = pd.DataFrame({'Missing %' :df_concat_na})\n",
    "missing_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:45.673187Z",
     "iopub.status.busy": "2022-01-19T22:39:45.672776Z",
     "iopub.status.idle": "2022-01-19T22:39:46.243612Z",
     "shell.execute_reply": "2022-01-19T22:39:46.24291Z",
     "shell.execute_reply.started": "2022-01-19T22:39:45.673152Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualizing missing values by feauture\n",
    "sns.barplot(x=df_concat_na.index, y=df_concat_na)\n",
    "plt.xticks(rotation='90')\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('% of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see on where we need to focus our work.\n",
    "1. Coming up with a strategy to the missing values with over 80% NAs\n",
    "2. Defining approach in imputing other missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values\n",
    "We will handle missing values by descending order of %NA. For each feature we'll first learn what we can from the description provided with the datasets, and secondly, provide our method for dealing with the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PoolQC:** Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "       \n",
    "As NA means 'No Pool' we can safely assume a missing value equates to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.24508Z",
     "iopub.status.busy": "2022-01-19T22:39:46.244824Z",
     "iopub.status.idle": "2022-01-19T22:39:46.250899Z",
     "shell.execute_reply": "2022-01-19T22:39:46.249928Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.245042Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['PoolQC'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T03:07:13.080149Z",
     "iopub.status.busy": "2022-01-18T03:07:13.079825Z",
     "iopub.status.idle": "2022-01-18T03:07:13.086762Z",
     "shell.execute_reply": "2022-01-18T03:07:13.085518Z",
     "shell.execute_reply.started": "2022-01-18T03:07:13.080109Z"
    }
   },
   "source": [
    "**MiscFeature**: Miscellaneous feature not covered in other categories\n",
    "\t\t\n",
    "       Elev\tElevator\n",
    "       Gar2\t2nd Garage (if not described in garage section)\n",
    "       Othr\tOther\n",
    "       Shed\tShed (over 100 SF)\n",
    "       TenC\tTennis Court\n",
    "       NA\tNone\n",
    "\n",
    "Equally here, NA refers to lack of this feature. No misc. features means we can again apply a 'None' fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.252331Z",
     "iopub.status.busy": "2022-01-19T22:39:46.252125Z",
     "iopub.status.idle": "2022-01-19T22:39:46.263695Z",
     "shell.execute_reply": "2022-01-19T22:39:46.262933Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.252306Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['MiscFeature'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alley**: Type of alley access to property\n",
    "\n",
    "       Grvl\tGravel\n",
    "       Pave\tPaved\n",
    "       NA \tNo alley access\n",
    "       \n",
    "NA means lack of this feature, so we fill missing values with None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.2659Z",
     "iopub.status.busy": "2022-01-19T22:39:46.26542Z",
     "iopub.status.idle": "2022-01-19T22:39:46.276563Z",
     "shell.execute_reply": "2022-01-19T22:39:46.275759Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.265837Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['Alley'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fence: Fence quality\n",
    "\t\t\n",
    "       GdPrv\tGood Privacy\n",
    "       MnPrv\tMinimum Privacy\n",
    "       GdWo\tGood Wood\n",
    "       MnWw\tMinimum Wood/Wire\n",
    "       NA\tNo Fence\n",
    "\n",
    "NA means lack of this feature, so we fill missing values with None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.27797Z",
     "iopub.status.busy": "2022-01-19T22:39:46.277709Z",
     "iopub.status.idle": "2022-01-19T22:39:46.288267Z",
     "shell.execute_reply": "2022-01-19T22:39:46.287394Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.277939Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['Fence'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FireplaceQu**: Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "       \n",
    "NA means lack of this feature, so we fill missing values with None       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.290006Z",
     "iopub.status.busy": "2022-01-19T22:39:46.289656Z",
     "iopub.status.idle": "2022-01-19T22:39:46.302439Z",
     "shell.execute_reply": "2022-01-19T22:39:46.30151Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.289975Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['FireplaceQu'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LotFrontage**: Linear feet of street connected to property\n",
    "\n",
    "We assume here that neighborhoods contrain similar houses to fill in missing values by median LotFrontage per Neighborhood. Computing median has to be split per dataset, so as to not cause data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.304573Z",
     "iopub.status.busy": "2022-01-19T22:39:46.304004Z",
     "iopub.status.idle": "2022-01-19T22:39:46.323202Z",
     "shell.execute_reply": "2022-01-19T22:39:46.322094Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.304538Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat[\"LotFrontage\"] = df_concat.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.327821Z",
     "iopub.status.busy": "2022-01-19T22:39:46.327196Z",
     "iopub.status.idle": "2022-01-19T22:39:46.333768Z",
     "shell.execute_reply": "2022-01-19T22:39:46.332898Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.327782Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "v6 - Possible direction for future notebooks to compute missing values seperately\n",
    "\n",
    "train_copy = train.copy(deep=True)\n",
    "train_copy.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "LotF_median_train = train_copy['LotFrontage']\n",
    "\n",
    "df_concat.iloc[:i_train]['LotFrontage'] = LotF_median_train\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GarageType**: Garage location\n",
    "\t\t\n",
    "       2Types\tMore than one type of garage\n",
    "       Attchd\tAttached to home\n",
    "       Basment\tBasement Garage\n",
    "       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n",
    "       CarPort\tCar Port\n",
    "       Detchd\tDetached from home\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "**GarageFinish**: Interior finish of the garage\n",
    "\n",
    "       Fin\tFinished\n",
    "       RFn\tRough Finished\t\n",
    "       Unf\tUnfinished\n",
    "       NA\tNo Garage\n",
    "\n",
    "**GarageQual**: Garage quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "**GarageCond**: Garage condition\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "       \n",
    "NA means lack of this feature, so we fill missing values with None       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.335887Z",
     "iopub.status.busy": "2022-01-19T22:39:46.334937Z",
     "iopub.status.idle": "2022-01-19T22:39:46.348982Z",
     "shell.execute_reply": "2022-01-19T22:39:46.348203Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.335828Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    df_concat[col].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GarageYrBlt**: Year garage was built\n",
    "\n",
    "**GarageCars**: Size of garage in car capacity\n",
    "\n",
    "**GarageArea**: Size of garage in square feet\n",
    "\n",
    "Missing numerical values will be replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.351035Z",
     "iopub.status.busy": "2022-01-19T22:39:46.350566Z",
     "iopub.status.idle": "2022-01-19T22:39:46.360669Z",
     "shell.execute_reply": "2022-01-19T22:39:46.359909Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.350972Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    df_concat[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BsmtQual**: Evaluates the height of the basement\n",
    "\n",
    "       Ex\tExcellent (100+ inches)\t\n",
    "       Gd\tGood (90-99 inches)\n",
    "       TA\tTypical (80-89 inches)\n",
    "       Fa\tFair (70-79 inches)\n",
    "       Po\tPoor (<70 inches\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "**BsmtCond**: Evaluates the general condition of the basement\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical - slight dampness allowed\n",
    "       Fa\tFair - dampness or some cracking or settling\n",
    "       Po\tPoor - Severe cracking, settling, or wetness\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "**BsmtExposure**: Refers to walkout or garden level walls\n",
    "\n",
    "       Gd\tGood Exposure\n",
    "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
    "       Mn\tMimimum Exposure\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "**BsmtFinType1**: Rating of basement finished area\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "**BsmtFinType2**: Rating of basement finished area (if multiple types)\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "       \n",
    "NA means lack of this feature, so we fill missing values with None.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.362326Z",
     "iopub.status.busy": "2022-01-19T22:39:46.361869Z",
     "iopub.status.idle": "2022-01-19T22:39:46.377603Z",
     "shell.execute_reply": "2022-01-19T22:39:46.376615Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.362288Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):    \n",
    "    df_concat[col].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BsmtFinSF1**: Type 1 finished square feet\n",
    "\n",
    "**BsmtFinSF2**: Type 2 finished square feet\n",
    "\n",
    "**BsmtUnfSF**: Unfinished square feet of basement area\n",
    "\n",
    "**TotalBsmtSF**: Total square feet of basement area\n",
    "\n",
    "**BsmtFullBath**: Basement full bathrooms\n",
    "\n",
    "**BsmtHalfBath**: Basement half bathrooms\n",
    "\n",
    "Missing numerical values will be replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.379509Z",
     "iopub.status.busy": "2022-01-19T22:39:46.378776Z",
     "iopub.status.idle": "2022-01-19T22:39:46.393918Z",
     "shell.execute_reply": "2022-01-19T22:39:46.393127Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.379469Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtHalfBath', 'BsmtFullBath'):\n",
    "    df_concat[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MasVnrType**: Masonry veneer type\n",
    "\n",
    "       BrkCmn\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       None\tNone\n",
    "       Stone\tStone\n",
    "       \n",
    "Missing values will be categorized as None       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.395869Z",
     "iopub.status.busy": "2022-01-19T22:39:46.395263Z",
     "iopub.status.idle": "2022-01-19T22:39:46.403094Z",
     "shell.execute_reply": "2022-01-19T22:39:46.40238Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.395823Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['MasVnrType'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MasVnrArea** : Masonry veneer area in square feet\n",
    "As an architect I'm astonished this feature even exists. We assume missing values mean no masonry veneer, meaning 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.405105Z",
     "iopub.status.busy": "2022-01-19T22:39:46.404757Z",
     "iopub.status.idle": "2022-01-19T22:39:46.41661Z",
     "shell.execute_reply": "2022-01-19T22:39:46.415771Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.405065Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['MasVnrArea'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSZoning**: Identifies the general zoning classification of the sale.\n",
    "\t\t\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "       \n",
    "As RL is by far the most common, we take the mode and fill in missing values with RL.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.41822Z",
     "iopub.status.busy": "2022-01-19T22:39:46.417905Z",
     "iopub.status.idle": "2022-01-19T22:39:46.43107Z",
     "shell.execute_reply": "2022-01-19T22:39:46.4301Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.418179Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.433234Z",
     "iopub.status.busy": "2022-01-19T22:39:46.432093Z",
     "iopub.status.idle": "2022-01-19T22:39:46.440779Z",
     "shell.execute_reply": "2022-01-19T22:39:46.440119Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.433185Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['MSZoning'].fillna('RL', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilities**: Type of utilities available\n",
    "\t\t\n",
    "       AllPub\tAll public Utilities (E,G,W,& S)\t\n",
    "       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n",
    "       NoSeWa\tElectricity and Gas Only\n",
    "       ELO\tElectricity only\n",
    "       \n",
    "The value of this feauture is AllPub for most of the dataset, with only 1 NoSeWa feauture. We can fately assume this feauture will not be helpful in predictive modelling, and will remove it.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.442358Z",
     "iopub.status.busy": "2022-01-19T22:39:46.442004Z",
     "iopub.status.idle": "2022-01-19T22:39:46.45475Z",
     "shell.execute_reply": "2022-01-19T22:39:46.453818Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.442318Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.456181Z",
     "iopub.status.busy": "2022-01-19T22:39:46.455916Z",
     "iopub.status.idle": "2022-01-19T22:39:46.46764Z",
     "shell.execute_reply": "2022-01-19T22:39:46.46674Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.456151Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat.drop(['Utilities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functional**: Home functionality (Assume typical unless deductions are warranted)\n",
    "\n",
    "       Typ\tTypical Functionality\n",
    "       Min1\tMinor Deductions 1\n",
    "       Min2\tMinor Deductions 2\n",
    "       Mod\tModerate Deductions\n",
    "       Maj1\tMajor Deductions 1\n",
    "       Maj2\tMajor Deductions 2\n",
    "       Sev\tSeverely Damaged\n",
    "       Sal\tSalvage only\n",
    "       \n",
    "Any missing values will be transformed to Typ.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.469171Z",
     "iopub.status.busy": "2022-01-19T22:39:46.468711Z",
     "iopub.status.idle": "2022-01-19T22:39:46.477256Z",
     "shell.execute_reply": "2022-01-19T22:39:46.476382Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.469132Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['Functional'].fillna('Typ', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Electrical**: Electrical system\n",
    "\n",
    "       SBrkr\tStandard Circuit Breakers & Romex\n",
    "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
    "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix\tMixed\n",
    "       \n",
    "It's only NA value will be set to SBrkr.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.478784Z",
     "iopub.status.busy": "2022-01-19T22:39:46.478229Z",
     "iopub.status.idle": "2022-01-19T22:39:46.489624Z",
     "shell.execute_reply": "2022-01-19T22:39:46.488928Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.478745Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['Electrical'].fillna('SBrkr', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KitchenQual**: Kitchen quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       \n",
    "We replace its only missing value by the mode of TA       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.491703Z",
     "iopub.status.busy": "2022-01-19T22:39:46.490757Z",
     "iopub.status.idle": "2022-01-19T22:39:46.50243Z",
     "shell.execute_reply": "2022-01-19T22:39:46.501712Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.491648Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['KitchenQual'].fillna('TA', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exterior1st**: Exterior covering on house\n",
    "**Exterior2nd**: Exterior covering on house (if more than one material)\n",
    "\n",
    "       AsbShng\tAsbestos Shingles\n",
    "       AsphShn\tAsphalt Shingles\n",
    "       BrkComm\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       CemntBd\tCement Board\n",
    "       HdBoard\tHard Board\n",
    "       ImStucc\tImitation Stucco\n",
    "       MetalSd\tMetal Siding\n",
    "       Other\tOther\n",
    "       Plywood\tPlywood\n",
    "       PreCast\tPreCast\t\n",
    "       Stone\tStone\n",
    "       Stucco\tStucco\n",
    "       VinylSd\tVinyl Siding\n",
    "       Wd Sdng\tWood Siding\n",
    "       WdShing\tWood Shingles\n",
    "\n",
    "Since both have a single missing value we again replace the most common string as the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.503918Z",
     "iopub.status.busy": "2022-01-19T22:39:46.503366Z",
     "iopub.status.idle": "2022-01-19T22:39:46.513149Z",
     "shell.execute_reply": "2022-01-19T22:39:46.512504Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.503883Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['Exterior1st'].fillna('TA', inplace=True)\n",
    "df_concat['Exterior2nd'].fillna('TA', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SaleType**: Type of sale\n",
    "\t\t\n",
    "       WD \tWarranty Deed - Conventional\n",
    "       CWD\tWarranty Deed - Cash\n",
    "       VWD\tWarranty Deed - VA Loan\n",
    "       New\tHome just constructed and sold\n",
    "       COD\tCourt Officer Deed/Estate\n",
    "       Con\tContract 15% Down payment regular terms\n",
    "       ConLw\tContract Low Down payment and low interest\n",
    "       ConLI\tContract Low Interest\n",
    "       ConLD\tContract Low Down\n",
    "       Oth\tOther\n",
    "       \n",
    "Missing values will be filled with most frequent type WD       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.514579Z",
     "iopub.status.busy": "2022-01-19T22:39:46.514053Z",
     "iopub.status.idle": "2022-01-19T22:39:46.526193Z",
     "shell.execute_reply": "2022-01-19T22:39:46.52541Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.514544Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['SaleType'].fillna('WD', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.52803Z",
     "iopub.status.busy": "2022-01-19T22:39:46.527261Z",
     "iopub.status.idle": "2022-01-19T22:39:46.551942Z",
     "shell.execute_reply": "2022-01-19T22:39:46.551085Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.527986Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating dataframe with percentages of missing values\n",
    "df_concat_na = (df_concat.isnull().sum() / len(df_concat)) * 100\n",
    "\n",
    "#Sorting by percentages of missing values\n",
    "df_concat_na = df_concat_na.sort_values(ascending=False) \n",
    "\n",
    "missing_values = pd.DataFrame({'Missing %' :df_concat_na})\n",
    "missing_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "Simple (simplified) encoding.\n",
    "\n",
    "Future version: Transforming ordinal and nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.553861Z",
     "iopub.status.busy": "2022-01-19T22:39:46.553553Z",
     "iopub.status.idle": "2022-01-19T22:39:46.559501Z",
     "shell.execute_reply": "2022-01-19T22:39:46.558924Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.553806Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Ordinal features\n",
    "ordinal_to_encode=['LandSlope','YearBuilt','YearRemodAdd','CentralAir','GarageYrBlt','PavedDrive','YrSold']\n",
    "\n",
    "#Encoding features for model with LabelEncoder\n",
    "for field in ordinal_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    df_concat[field] = le.fit_transform(df_concat[field].values)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.560998Z",
     "iopub.status.busy": "2022-01-19T22:39:46.560545Z",
     "iopub.status.idle": "2022-01-19T22:39:46.568835Z",
     "shell.execute_reply": "2022-01-19T22:39:46.568169Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.560964Z"
    }
   },
   "outputs": [],
   "source": [
    "#ordinal_ready = ['OverallQual','OverallCond','MoSold','FullBath','KitchenAbvGr','TotRmsAbvGrd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.570956Z",
     "iopub.status.busy": "2022-01-19T22:39:46.569938Z",
     "iopub.status.idle": "2022-01-19T22:39:46.58265Z",
     "shell.execute_reply": "2022-01-19T22:39:46.581861Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.570908Z"
    }
   },
   "outputs": [],
   "source": [
    "'''ordinal_mappings = {\n",
    "    \"MSSubClass\": ['None', 20, 30,40,45,50,60,70,75,80,85, 90,120,150,160,180,190], \n",
    "    \"ExterQual\": ['None','Fa','TA','Gd','Ex'], \n",
    "    \"LotShape\": ['None','Reg','IR1' ,'IR2','IR3'], \n",
    "    \"BsmtQual\": ['None','Fa','TA','Gd','Ex'], \n",
    "    \"BsmtCond\": ['None','Po','Fa','TA','Gd','Ex'], \n",
    "    \"BsmtExposure\": ['None','No','Mn','Av','Gd'], \n",
    "    \"BsmtFinType1\": ['None','Unf','LwQ', 'Rec','BLQ','ALQ' , 'GLQ' ], \n",
    "    \"BsmtFinType2\": ['None','Unf','LwQ', 'Rec','BLQ','ALQ' , 'GLQ' ], \n",
    "    \"HeatingQC\": ['None','Po','Fa','TA','Gd','Ex'], \n",
    "    \"Functional\": ['None','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'], \n",
    "    \"FireplaceQu\": ['None','Po','Fa','TA','Gd','Ex'], \n",
    "    \"KitchenQual\": ['None','Fa','TA','Gd','Ex'], \n",
    "    \"GarageFinish\": ['None','Unf','RFn','Fin'], \n",
    "    \"GarageQual\": ['None','Po','Fa','TA','Gd','Ex'], \n",
    "    \"GarageCond\": ['None','Po','Fa','TA','Gd','Ex'], \n",
    "    \"PoolQC\": ['None','Fa','Gd','Ex'], \n",
    "    \"Fence\": ['None','MnWw','GdWo','MnPrv','GdPrv'],\n",
    "}\n",
    "\n",
    "# transform to a suitable format for ce.OrdinalEncoder\n",
    "ce_ordinal_mappings = []\n",
    "for col, unique_values in ordinal_mappings.items():\n",
    "    local_mapping = {val:idx for idx, val in enumerate(unique_values)}\n",
    "    ce_ordinal_mappings.append({\"col\":col, \"mapping\":local_mapping})\n",
    "    \n",
    "encoder = ce.OrdinalEncoder(mapping=ce_ordinal_mappings, return_df=True)\n",
    "encoder.fit_transform(train_X)\n",
    "encoder.transform(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.588756Z",
     "iopub.status.busy": "2022-01-19T22:39:46.58852Z",
     "iopub.status.idle": "2022-01-19T22:39:46.609572Z",
     "shell.execute_reply": "2022-01-19T22:39:46.608566Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.588729Z"
    }
   },
   "outputs": [],
   "source": [
    "#MSSubClass\n",
    "df_concat['MSSubClass'].astype(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "df_concat['OverallCond'] = df_concat['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "df_concat['YrSold'] = df_concat['YrSold'].astype(str)\n",
    "df_concat['MoSold'] = df_concat['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.611975Z",
     "iopub.status.busy": "2022-01-19T22:39:46.610927Z",
     "iopub.status.idle": "2022-01-19T22:39:46.671879Z",
     "shell.execute_reply": "2022-01-19T22:39:46.67117Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.611931Z"
    }
   },
   "outputs": [],
   "source": [
    "#List of features to encode\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "#Applying LabelEncoder to categorical features\n",
    "for i in cols:\n",
    "    le = LabelEncoder() \n",
    "    le.fit(list(df_concat[i].values)) \n",
    "    df_concat[i] = le.transform(list(df_concat[i].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding a Total sqf feature**\n",
    "\n",
    "Since we've seen the correlation between square footage on SalePrice, adding a feature combing all seperate parameters together seems logical as a great predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.673185Z",
     "iopub.status.busy": "2022-01-19T22:39:46.672971Z",
     "iopub.status.idle": "2022-01-19T22:39:46.678813Z",
     "shell.execute_reply": "2022-01-19T22:39:46.678169Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.673161Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat['TotalSF'] = df_concat['TotalBsmtSF'] + df_concat['1stFlrSF'] + df_concat['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness and Box Cox Transformation\n",
    "Calculating degree of skewness and computing Box Cox transformation of 1 + x\n",
    "\n",
    "*Note: applying Box Cox transformation to both datasets at once will lead to data leakage and will be addressed in future versions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.680679Z",
     "iopub.status.busy": "2022-01-19T22:39:46.680256Z",
     "iopub.status.idle": "2022-01-19T22:39:46.716928Z",
     "shell.execute_reply": "2022-01-19T22:39:46.716336Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.680635Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_feats = df_concat.dtypes[df_concat.dtypes != \"object\"].index\n",
    "\n",
    "#Check the skew of all numerical features\n",
    "skewed_feats = df_concat[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.71872Z",
     "iopub.status.busy": "2022-01-19T22:39:46.718086Z",
     "iopub.status.idle": "2022-01-19T22:39:46.743533Z",
     "shell.execute_reply": "2022-01-19T22:39:46.742819Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.718689Z"
    }
   },
   "outputs": [],
   "source": [
    "skewness = skewness[abs(skewness.Skew)>0.75]\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #df_concat[feat] += 1\n",
    "    df_concat[feat] = boxcox1p(df_concat[feat], lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.745259Z",
     "iopub.status.busy": "2022-01-19T22:39:46.74482Z",
     "iopub.status.idle": "2022-01-19T22:39:46.775444Z",
     "shell.execute_reply": "2022-01-19T22:39:46.774709Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.745228Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat = pd.get_dummies(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating new training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.777215Z",
     "iopub.status.busy": "2022-01-19T22:39:46.776775Z",
     "iopub.status.idle": "2022-01-19T22:39:46.781677Z",
     "shell.execute_reply": "2022-01-19T22:39:46.780964Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.777183Z"
    }
   },
   "outputs": [],
   "source": [
    "train = df_concat[:i_train]\n",
    "test = df_concat[i_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.782895Z",
     "iopub.status.busy": "2022-01-19T22:39:46.782676Z",
     "iopub.status.idle": "2022-01-19T22:39:46.794056Z",
     "shell.execute_reply": "2022-01-19T22:39:46.792937Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.78287Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating cross validation strategy with shuffle\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=0).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LASSO Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.796099Z",
     "iopub.status.busy": "2022-01-19T22:39:46.795547Z",
     "iopub.status.idle": "2022-01-19T22:39:46.806254Z",
     "shell.execute_reply": "2022-01-19T22:39:46.805191Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.796043Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic Net Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.808417Z",
     "iopub.status.busy": "2022-01-19T22:39:46.80782Z",
     "iopub.status.idle": "2022-01-19T22:39:46.82078Z",
     "shell.execute_reply": "2022-01-19T22:39:46.819919Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.808363Z"
    }
   },
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.822464Z",
     "iopub.status.busy": "2022-01-19T22:39:46.822084Z",
     "iopub.status.idle": "2022-01-19T22:39:46.834817Z",
     "shell.execute_reply": "2022-01-19T22:39:46.833921Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.822421Z"
    }
   },
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.836526Z",
     "iopub.status.busy": "2022-01-19T22:39:46.835992Z",
     "iopub.status.idle": "2022-01-19T22:39:46.847105Z",
     "shell.execute_reply": "2022-01-19T22:39:46.846309Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.836488Z"
    }
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.848706Z",
     "iopub.status.busy": "2022-01-19T22:39:46.848333Z",
     "iopub.status.idle": "2022-01-19T22:39:46.86791Z",
     "shell.execute_reply": "2022-01-19T22:39:46.866843Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.848664Z"
    }
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =0, nthread = -1,\n",
    "                             verbosity = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.870123Z",
     "iopub.status.busy": "2022-01-19T22:39:46.869344Z",
     "iopub.status.idle": "2022-01-19T22:39:46.878705Z",
     "shell.execute_reply": "2022-01-19T22:39:46.878029Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.870071Z"
    }
   },
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,\n",
    "                              verbose_eval = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:46.880859Z",
     "iopub.status.busy": "2022-01-19T22:39:46.880376Z",
     "iopub.status.idle": "2022-01-19T22:39:47.659223Z",
     "shell.execute_reply": "2022-01-19T22:39:47.658265Z",
     "shell.execute_reply.started": "2022-01-19T22:39:46.880814Z"
    }
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:47.661805Z",
     "iopub.status.busy": "2022-01-19T22:39:47.660891Z",
     "iopub.status.idle": "2022-01-19T22:39:48.466248Z",
     "shell.execute_reply": "2022-01-19T22:39:48.465376Z",
     "shell.execute_reply.started": "2022-01-19T22:39:47.661749Z"
    }
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:48.468205Z",
     "iopub.status.busy": "2022-01-19T22:39:48.467669Z",
     "iopub.status.idle": "2022-01-19T22:39:48.814862Z",
     "shell.execute_reply": "2022-01-19T22:39:48.813931Z",
     "shell.execute_reply.started": "2022-01-19T22:39:48.468158Z"
    }
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:39:48.817076Z",
     "iopub.status.busy": "2022-01-19T22:39:48.816526Z",
     "iopub.status.idle": "2022-01-19T22:40:34.43545Z",
     "shell.execute_reply": "2022-01-19T22:40:34.43436Z",
     "shell.execute_reply.started": "2022-01-19T22:39:48.817027Z"
    }
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:40:34.437346Z",
     "iopub.status.busy": "2022-01-19T22:40:34.436933Z",
     "iopub.status.idle": "2022-01-19T22:41:34.118682Z",
     "shell.execute_reply": "2022-01-19T22:41:34.117783Z",
     "shell.execute_reply.started": "2022-01-19T22:40:34.437298Z"
    }
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:41:34.120335Z",
     "iopub.status.busy": "2022-01-19T22:41:34.120045Z",
     "iopub.status.idle": "2022-01-19T22:41:36.261575Z",
     "shell.execute_reply": "2022-01-19T22:41:36.260697Z",
     "shell.execute_reply.started": "2022-01-19T22:41:34.120292Z"
    }
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Models\n",
    "\n",
    "\n",
    "**Average Base Models**\n",
    "\n",
    "Building a new scaleable class to extend scikit-learn with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:41:36.263898Z",
     "iopub.status.busy": "2022-01-19T22:41:36.263032Z",
     "iopub.status.idle": "2022-01-19T22:41:36.271785Z",
     "shell.execute_reply": "2022-01-19T22:41:36.270922Z",
     "shell.execute_reply.started": "2022-01-19T22:41:36.263835Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    #Define clones of original models to fit the data\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        #Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Predictions for cloned models and get average\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Base Models Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:41:36.273556Z",
     "iopub.status.busy": "2022-01-19T22:41:36.273022Z",
     "iopub.status.idle": "2022-01-19T22:42:23.389008Z",
     "shell.execute_reply": "2022-01-19T22:42:23.387942Z",
     "shell.execute_reply.started": "2022-01-19T22:41:36.273511Z"
    }
   },
   "outputs": [],
   "source": [
    "averaged_models = AverageModels(models = (lasso, ENet, GBoost, KRR))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the simplest stacking approach offers great improvement to our score, and encouragement to keep exploring further options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meta-model**\n",
    "\n",
    "In this model of models we use our base models to train a new meta-model. That's a lot of models.\n",
    "\n",
    "1. Create train and holdout sets\n",
    "2. Train base models on train set\n",
    "3. Test base models on holdout\n",
    "4. Use predictions as output to train meta-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking Averaged Base Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:42:23.396913Z",
     "iopub.status.busy": "2022-01-19T22:42:23.39433Z",
     "iopub.status.idle": "2022-01-19T22:42:23.415504Z",
     "shell.execute_reply": "2022-01-19T22:42:23.414554Z",
     "shell.execute_reply.started": "2022-01-19T22:42:23.396839Z"
    }
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    #Fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        #Train the cloned meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Predictions of all base models on test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking Averaged Models Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:42:23.423455Z",
     "iopub.status.busy": "2022-01-19T22:42:23.420889Z",
     "iopub.status.idle": "2022-01-19T22:45:50.392532Z",
     "shell.execute_reply": "2022-01-19T22:45:50.389321Z",
     "shell.execute_reply.started": "2022-01-19T22:42:23.423392Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensembling StackedRegressor, XGBoost and LightGBM** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:45:50.394679Z",
     "iopub.status.busy": "2022-01-19T22:45:50.394358Z",
     "iopub.status.idle": "2022-01-19T22:45:50.405264Z",
     "shell.execute_reply": "2022-01-19T22:45:50.404183Z",
     "shell.execute_reply.started": "2022-01-19T22:45:50.394635Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacked Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:45:50.410937Z",
     "iopub.status.busy": "2022-01-19T22:45:50.410192Z",
     "iopub.status.idle": "2022-01-19T22:46:37.981957Z",
     "shell.execute_reply": "2022-01-19T22:46:37.981055Z",
     "shell.execute_reply.started": "2022-01-19T22:45:50.410883Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:46:37.98423Z",
     "iopub.status.busy": "2022-01-19T22:46:37.983617Z",
     "iopub.status.idle": "2022-01-19T22:46:48.864783Z",
     "shell.execute_reply": "2022-01-19T22:46:48.863863Z",
     "shell.execute_reply.started": "2022-01-19T22:46:37.98418Z"
    }
   },
   "outputs": [],
   "source": [
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:46:48.866291Z",
     "iopub.status.busy": "2022-01-19T22:46:48.866011Z",
     "iopub.status.idle": "2022-01-19T22:46:49.269626Z",
     "shell.execute_reply": "2022-01-19T22:46:49.26874Z",
     "shell.execute_reply.started": "2022-01-19T22:46:48.866251Z"
    }
   },
   "outputs": [],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSLE score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:46:49.271764Z",
     "iopub.status.busy": "2022-01-19T22:46:49.271208Z",
     "iopub.status.idle": "2022-01-19T22:46:49.277766Z",
     "shell.execute_reply": "2022-01-19T22:46:49.276933Z",
     "shell.execute_reply.started": "2022-01-19T22:46:49.271721Z"
    }
   },
   "outputs": [],
   "source": [
    "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
    "               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:46:49.280176Z",
     "iopub.status.busy": "2022-01-19T22:46:49.279582Z",
     "iopub.status.idle": "2022-01-19T22:46:49.288955Z",
     "shell.execute_reply": "2022-01-19T22:46:49.288208Z",
     "shell.execute_reply.started": "2022-01-19T22:46:49.280134Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T22:46:49.29271Z",
     "iopub.status.busy": "2022-01-19T22:46:49.292162Z",
     "iopub.status.idle": "2022-01-19T22:46:49.306411Z",
     "shell.execute_reply": "2022-01-19T22:46:49.305743Z",
     "shell.execute_reply.started": "2022-01-19T22:46:49.292675Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = ensemble\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits & Inspiration\n",
    "* [Stacked Regression by Serigne](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard/notebook) - Absolutely stunning notebook that I've used as the template for my own explorations here. Taught me a lot about feature engineering and stacked modelling.\n",
    "* [Stacking Ensemble Machine Learning With Python by Jason Brownlee](https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/) - Great tutorial on stacking models\n",
    "* [Comprehensive data exploration with Python by Pedro Marcelino](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) - In-depth EDA on this dataset\n",
    "* [A study on Regression applied to the Ames dataset by juliencs](https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset) - Great notebook using linear regression on this dataset\n",
    "* [Missing Values, Ordinal data and stories\n",
    " by mitra mirshafiee](https://www.kaggle.com/mitramir5/missing-values-ordinal-data-and-stories) - Illustrative and educational notebook on handling missing values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
